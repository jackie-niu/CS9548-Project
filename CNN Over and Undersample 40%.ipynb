{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuKIFcxpbk7H"
      },
      "source": [
        "# Crime Classification – CS 9548 Project\n",
        "**Goal:** Exploring Machine Learning Techniques for Image Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKK32z3dbeIh",
        "outputId": "ac03f7c1-ddfa-4415-a42e-3e7ed88d33e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSayQtOQrtBS"
      },
      "source": [
        "## Download and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiKxeSBbrGH",
        "outputId": "0c0a228d-fdad-43b2-d25c-998a02ac243a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/odins0n/ucf-crime-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11.0G/11.0G [08:39<00:00, 22.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAAnRw4br3yB"
      },
      "source": [
        "## Create DataFrame of Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79zyumijenlM",
        "outputId": "5749f440-71b1-430a-ecc7-ac0d71cd9112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data dir: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Train\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Test\n",
            "label\n",
            "NormalVideos     947768\n",
            "Stealing          44802\n",
            "Robbery           41493\n",
            "Burglary          39504\n",
            "Arrest            26397\n",
            "Shoplifting       24835\n",
            "Fighting          24684\n",
            "Arson             24421\n",
            "RoadAccidents     23486\n",
            "Abuse             19076\n",
            "Explosion         18753\n",
            "Vandalism         13626\n",
            "Assault           10360\n",
            "Shooting           7140\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "NormalVideos     64952\n",
            "Burglary          7657\n",
            "Shooting          7630\n",
            "Shoplifting       7623\n",
            "Explosion         6510\n",
            "Arrest            3365\n",
            "Arson             2793\n",
            "RoadAccidents     2663\n",
            "Assault           2657\n",
            "Stealing          1984\n",
            "Fighting          1231\n",
            "Vandalism         1111\n",
            "Robbery            835\n",
            "Abuse              297\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "# Get directories of train and test datasets\n",
        "data_dir = pathlib.Path(path)\n",
        "train_dir = data_dir / \"Train\"\n",
        "test_dir = data_dir / \"Test\"\n",
        "\n",
        "print(\"Data dir:\", data_dir)\n",
        "print(train_dir)\n",
        "print(test_dir)\n",
        "\n",
        "# Function to build dataframe\n",
        "def build_image_df(root_dir):\n",
        "    root_dir = pathlib.Path(root_dir)\n",
        "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for p in image_paths:\n",
        "        label = p.parent.name\n",
        "        rows.append({\"image\": str(p), \"label\": label})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Build train and test dataframes\n",
        "train = build_image_df(train_dir)\n",
        "test = build_image_df(test_dir)\n",
        "\n",
        "print(train['label'].value_counts())\n",
        "print(test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04OgKDsqxxW7"
      },
      "source": [
        "## Encode Label as Integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8URqILnwt2WI",
        "outputId": "32939ad4-9c02-4b25-dd0c-76509bb33838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 14\n",
            "Class name vs label_idx:\n",
            "0 Abuse\n",
            "1 Arrest\n",
            "2 Arson\n",
            "3 Assault\n",
            "4 Burglary\n",
            "5 Explosion\n",
            "6 Fighting\n",
            "7 NormalVideos\n",
            "8 RoadAccidents\n",
            "9 Robbery\n",
            "10 Shooting\n",
            "11 Shoplifting\n",
            "12 Stealing\n",
            "13 Vandalism\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit label encoder on training labels\n",
        "le = LabelEncoder()\n",
        "train['label_idx'] = le.fit_transform(train['label'])\n",
        "\n",
        "# Apply the same encoding to test labels\n",
        "test['label_idx'] = le.transform(test['label'])\n",
        "\n",
        "# Number of classes and mapping\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class name vs label_idx:\")\n",
        "for index, cls in enumerate(le.classes_):\n",
        "    print(index, cls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zpNQ1fvB7CT"
      },
      "source": [
        "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling, as well as data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QqbjHTTIj2c"
      },
      "source": [
        "## Add Video Column ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WwouvCRwIjAJ"
      },
      "outputs": [],
      "source": [
        "def extract_video_id(path_str):\n",
        "    stem = pathlib.Path(path_str).stem\n",
        "\n",
        "    # split off the last chunk\n",
        "    video_id = stem.rsplit(\"_\", 1)[0]\n",
        "\n",
        "    return video_id\n",
        "\n",
        "train['video_id'] = train['image'].apply(extract_video_id)\n",
        "test['video_id']  = test['image'].apply(extract_video_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2iqmT3H-ZHG"
      },
      "source": [
        "## Split Train Into Train and Val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmdPhvLV-a0K",
        "outputId": "9c2ad22c-09c3-4d9b-96f7-670a84440069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Num train videos: 1288\n",
            "Num val videos: 322\n",
            "Train frames: 1062923\n",
            "Val frames: 203422\n",
            "Test frames: 111308\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "unique_videos = train['video_id'].unique()\n",
        "\n",
        "video_labels = (\n",
        "    train.groupby('video_id')['label_idx'].agg(lambda x: np.bincount(x).argmax()).reindex(unique_videos)\n",
        ")\n",
        "\n",
        "# 80% train 20% val\n",
        "train_vids, val_vids = train_test_split(\n",
        "    unique_videos,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=video_labels\n",
        ")\n",
        "\n",
        "train_df_raw = train[train['video_id'].isin(train_vids)].reset_index(drop=True)\n",
        "val = train[train['video_id'].isin(val_vids)].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nNum train videos:\", len(train_vids))\n",
        "print(\"Num val videos:\", len(val_vids))\n",
        "print(\"Train frames:\", len(train_df_raw))\n",
        "print(\"Val frames:\", len(val))\n",
        "print(\"Test frames:\", len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3sNtMlKU9Py"
      },
      "source": [
        "## Under/Oversampling, Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jLVIQV3YCUpP"
      },
      "outputs": [],
      "source": [
        "TARGET = 10000\n",
        "\n",
        "def balance_dataset(df):\n",
        "    balanced_parts = []\n",
        "\n",
        "    for cls, group in df.groupby(\"label\"):\n",
        "        count = len(group)\n",
        "\n",
        "        if count < TARGET:\n",
        "            # Oversample to 10,000\n",
        "            group = group.sample(\n",
        "                n=TARGET,\n",
        "                replace=True,\n",
        "                random_state=42\n",
        "            )\n",
        "        else:\n",
        "            # Undersample to 10,000\n",
        "            group = group.sample(\n",
        "                n=TARGET,\n",
        "                replace=False,\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "        balanced_parts.append(group)\n",
        "\n",
        "    return pd.concat(balanced_parts).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train = balance_dataset(train_df_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpE-FRgGWbIg",
        "outputId": "4921a20e-1a9c-4559-9592-411f573a9b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "Burglary         10000\n",
            "Vandalism        10000\n",
            "Explosion        10000\n",
            "Robbery          10000\n",
            "Arson            10000\n",
            "NormalVideos     10000\n",
            "Abuse            10000\n",
            "Stealing         10000\n",
            "Assault          10000\n",
            "Fighting         10000\n",
            "RoadAccidents    10000\n",
            "Shooting         10000\n",
            "Shoplifting      10000\n",
            "Arrest           10000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train['label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfhjEsJsKTz6"
      },
      "source": [
        "## Set up PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AXeau7INGq3K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Set constants for PyTorch\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqf9D2jzPiiC"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "P6VHgGIaPkQs"
      },
      "outputs": [],
      "source": [
        "# Data augmentation to training dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)),\n",
        "    transforms.ColorJitter(contrast=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Simple transforms to val/test dataset\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9SfD-Yoe5WJ"
      },
      "source": [
        "## Create Pipeline For PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x7MPkUfJe4Ms"
      },
      "outputs": [],
      "source": [
        "class CrimeDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image']\n",
        "        label = int(row['label_idx'])\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Transform if needed (might not need for val/test)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrSFo_31fsiQ"
      },
      "source": [
        "## Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pMXciaJZN6tv"
      },
      "outputs": [],
      "source": [
        "# First convert to CrimeDataset classes\n",
        "train_dataset = CrimeDataset(train, train_transform)\n",
        "val_dataset = CrimeDataset(val, eval_transform)\n",
        "test_dataset = CrimeDataset(test, eval_transform)\n",
        "\n",
        "# Transform to DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzyFAt9lKxkF",
        "outputId": "c5808144-41d6-4203-a696-f4f0add7f785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample batch shapes -> images: torch.Size([32, 3, 64, 64]) labels: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"\\nSample batch shapes -> images:\", images.shape, \"labels:\", labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsl42desQDEF"
      },
      "source": [
        "## Create CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7CB06lIQI-S",
        "outputId": "ae2bd694-ed77-415e-d30e-9877f8c599b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten_dim = 128 * 8 * 8\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_dim, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = Net(num_classes=num_classes).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oald1KXZTIsl"
      },
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oLnKSq4dTKlR"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZDvgQ4BRG1CD"
      },
      "outputs": [],
      "source": [
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H06Mj3Mfh4xo",
        "outputId": "850b6193-e55e-4bf9-eb2a-998a7cb168a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.9290, Train Acc: 0.7133 | Val Loss: 2.5391, Val Acc: 0.2456\n",
            "Epoch 2/10 | Train Loss: 0.3913, Train Acc: 0.8801 | Val Loss: 2.4473, Val Acc: 0.3659\n",
            "Epoch 3/10 | Train Loss: 0.2841, Train Acc: 0.9130 | Val Loss: 2.6583, Val Acc: 0.4196\n",
            "Epoch 4/10 | Train Loss: 0.2350, Train Acc: 0.9274 | Val Loss: 2.6409, Val Acc: 0.4719\n",
            "Epoch 5/10 | Train Loss: 0.2037, Train Acc: 0.9378 | Val Loss: 2.7676, Val Acc: 0.4730\n",
            "Epoch 6/10 | Train Loss: 0.1813, Train Acc: 0.9440 | Val Loss: 2.6939, Val Acc: 0.4472\n",
            "Epoch 7/10 | Train Loss: 0.1656, Train Acc: 0.9484 | Val Loss: 2.8119, Val Acc: 0.4786\n",
            "Epoch 8/10 | Train Loss: 0.1540, Train Acc: 0.9527 | Val Loss: 2.7903, Val Acc: 0.5236\n",
            "Epoch 9/10 | Train Loss: 0.1388, Train Acc: 0.9569 | Val Loss: 3.0680, Val Acc: 0.5200\n",
            "Epoch 10/10 | Train Loss: 0.1342, Train Acc: 0.9586 | Val Loss: 3.0186, Val Acc: 0.4774\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns194RJv2lFg",
        "outputId": "fbe866ae-d8fc-4559-f8ac-d621dbd6829f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.4159, Test Acc: 0.4000\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crime Classification – CS 9548 Project\n",
        "**Goal:** Exploring Machine Learning Techniques for Image Classification"
      ],
      "metadata": {
        "id": "uuKIFcxpbk7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKK32z3dbeIh",
        "outputId": "c253a431-028b-4a1b-f5a6-b43f5cc62871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Extract Dataset"
      ],
      "metadata": {
        "id": "LSayQtOQrtBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiKxeSBbrGH",
        "outputId": "d60ef426-803f-4e30-ef4b-355e0726c3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/odins0n/ucf-crime-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.0G/11.0G [08:24<00:00, 23.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataFrame of Images"
      ],
      "metadata": {
        "id": "EAAnRw4br3yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "# Get directories of train and test datasets\n",
        "data_dir = pathlib.Path(path)\n",
        "train_dir = data_dir / \"Train\"\n",
        "test_dir = data_dir / \"Test\"\n",
        "\n",
        "print(\"Data dir:\", data_dir)\n",
        "print(train_dir)\n",
        "print(test_dir)\n",
        "\n",
        "# Function to build dataframe\n",
        "def build_image_df(root_dir):\n",
        "    root_dir = pathlib.Path(root_dir)\n",
        "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for p in image_paths:\n",
        "        label = p.parent.name\n",
        "        rows.append({\"image\": str(p), \"label\": label})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Build train and test dataframes\n",
        "train_df = build_image_df(train_dir)\n",
        "test_df = build_image_df(test_dir)\n",
        "\n",
        "print(train_df['label'].value_counts())\n",
        "print(test_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79zyumijenlM",
        "outputId": "b688bc81-648b-422b-c4d1-c6faf7633b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dir: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Train\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Test\n",
            "label\n",
            "NormalVideos     947768\n",
            "Stealing          44802\n",
            "Robbery           41493\n",
            "Burglary          39504\n",
            "Arrest            26397\n",
            "Shoplifting       24835\n",
            "Fighting          24684\n",
            "Arson             24421\n",
            "RoadAccidents     23486\n",
            "Abuse             19076\n",
            "Explosion         18753\n",
            "Vandalism         13626\n",
            "Assault           10360\n",
            "Shooting           7140\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "NormalVideos     64952\n",
            "Burglary          7657\n",
            "Shooting          7630\n",
            "Shoplifting       7623\n",
            "Explosion         6510\n",
            "Arrest            3365\n",
            "Arson             2793\n",
            "RoadAccidents     2663\n",
            "Assault           2657\n",
            "Stealing          1984\n",
            "Fighting          1231\n",
            "Vandalism         1111\n",
            "Robbery            835\n",
            "Abuse              297\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Label as Integer"
      ],
      "metadata": {
        "id": "04OgKDsqxxW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit label encoder on training labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_idx'] = le.fit_transform(train_df['label'])\n",
        "\n",
        "# Apply the same encoding to test labels\n",
        "test_df['label_idx']  = le.transform(test_df['label'])\n",
        "\n",
        "# Number of classes and mapping\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class name vs label_idx:\")\n",
        "for index, cls in enumerate(le.classes_):\n",
        "    print(index, cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8URqILnwt2WI",
        "outputId": "765c7eb6-cb90-4e13-9508-3c9f782990b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 14\n",
            "Class name vs label_idx:\n",
            "0 Abuse\n",
            "1 Arrest\n",
            "2 Arson\n",
            "3 Assault\n",
            "4 Burglary\n",
            "5 Explosion\n",
            "6 Fighting\n",
            "7 NormalVideos\n",
            "8 RoadAccidents\n",
            "9 Robbery\n",
            "10 Shooting\n",
            "11 Shoplifting\n",
            "12 Stealing\n",
            "13 Vandalism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling, as well as data augmentation."
      ],
      "metadata": {
        "id": "3zpNQ1fvB7CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Video Column ID"
      ],
      "metadata": {
        "id": "1QqbjHTTIj2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_id(path_str):\n",
        "    stem = pathlib.Path(path_str).stem\n",
        "\n",
        "    # split off the last chunk\n",
        "    video_id = stem.rsplit(\"_\", 1)[0]\n",
        "\n",
        "    return video_id\n",
        "\n",
        "train_df['video_id'] = train_df['image'].apply(extract_video_id)\n",
        "test_df['video_id']  = test_df['image'].apply(extract_video_id)"
      ],
      "metadata": {
        "id": "WwouvCRwIjAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train Into Train and Val"
      ],
      "metadata": {
        "id": "e2iqmT3H-ZHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "unique_videos = train_df['video_id'].unique()\n",
        "\n",
        "video_labels = (\n",
        "    train_df.groupby('video_id')['label_idx'].agg(lambda x: np.bincount(x).argmax()).reindex(unique_videos)\n",
        ")\n",
        "\n",
        "# 80% train 20% val\n",
        "train_vids, val_vids = train_test_split(\n",
        "    unique_videos,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=video_labels\n",
        ")\n",
        "\n",
        "train_df_raw = train_df[train_df['video_id'].isin(train_vids)].reset_index(drop=True)\n",
        "val_df = train_df[train_df['video_id'].isin(val_vids)].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nNum train videos:\", len(train_vids))\n",
        "print(\"Num val videos:\", len(val_vids))\n",
        "print(\"Train frames:\", len(train_df_raw))\n",
        "print(\"Val frames:\", len(val_df))\n",
        "print(\"Test frames:\", len(test_df))"
      ],
      "metadata": {
        "id": "LmdPhvLV-a0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ba0ead-48f5-44d8-8d6b-d1fb2d4d8669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Num train videos: 1288\n",
            "Num val videos: 322\n",
            "Train frames: 1047139\n",
            "Val frames: 219206\n",
            "Test frames: 111308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Over/undersampling"
      ],
      "metadata": {
        "id": "C3sNtMlKU9Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 10000\n",
        "\n",
        "def balance_dataset(df):\n",
        "    balanced_parts = []\n",
        "\n",
        "    for cls, group in df.groupby(\"label\"):\n",
        "        count = len(group)\n",
        "\n",
        "        if count > TARGET:\n",
        "            # Only undersample big classes\n",
        "            group = group.sample(\n",
        "                n=TARGET,\n",
        "                replace=False,\n",
        "                random_state=42\n",
        "            )\n",
        "        # if count <= TARGET: keep as-is\n",
        "\n",
        "        balanced_parts.append(group)\n",
        "\n",
        "    return pd.concat(balanced_parts).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_df_used = balance_dataset(train_df_raw)"
      ],
      "metadata": {
        "id": "-vgbAuEsbusr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df_used['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpXWJOjHsvlW",
        "outputId": "200eb724-c572-40f3-d468-9f227d70483a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "Explosion        10000\n",
            "Abuse            10000\n",
            "Robbery          10000\n",
            "Burglary         10000\n",
            "Arrest           10000\n",
            "Fighting         10000\n",
            "RoadAccidents    10000\n",
            "Shoplifting      10000\n",
            "Arson            10000\n",
            "Stealing         10000\n",
            "NormalVideos     10000\n",
            "Vandalism         9669\n",
            "Assault           8955\n",
            "Shooting          5807\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up PyTorch"
      ],
      "metadata": {
        "id": "PfhjEsJsKTz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Set constants for PyTorch\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "AXeau7INGq3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "mqf9D2jzPiiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation to training dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)),\n",
        "    transforms.ColorJitter(contrast=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Simple transforms to val/test dataset\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "P6VHgGIaPkQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Pipeline For PyTorch"
      ],
      "metadata": {
        "id": "r9SfD-Yoe5WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrimeDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image']\n",
        "        label = int(row['label_idx'])\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Transform if needed (might not need for val/test)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "x7MPkUfJe4Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataLoaders"
      ],
      "metadata": {
        "id": "ZrSFo_31fsiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert to CrimeDataset classes\n",
        "train_dataset = CrimeDataset(train_df_used, train_transform)\n",
        "val_dataset = CrimeDataset(val_df, eval_transform)\n",
        "test_dataset = CrimeDataset(test_df, eval_transform)\n",
        "\n",
        "# Transform to DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "pMXciaJZN6tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"\\nSample batch shapes -> images:\", images.shape, \"labels:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzyFAt9lKxkF",
        "outputId": "8c9272ea-3913-4a83-d6be-9fc73b2c442a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample batch shapes -> images: torch.Size([32, 3, 64, 64]) labels: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ResNet18 Model"
      ],
      "metadata": {
        "id": "rsl42desQDEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Class-weighted loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Add L2 regularization via weight_decay\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "j7CB06lIQI-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8095303e-1dc7-43a6-b930-04ce90763f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 210MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing"
      ],
      "metadata": {
        "id": "Oald1KXZTIsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "oLnKSq4dTKlR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "ZDvgQ4BRG1CD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H06Mj3Mfh4xo",
        "outputId": "0a5c94f2-e2b6-4550-e9b2-f61655e01e85"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.4333, Train Acc: 0.8702 | Val Loss: 2.5429, Val Acc: 0.4623\n",
            "Epoch 2/10 | Train Loss: 0.1602, Train Acc: 0.9531 | Val Loss: 2.2687, Val Acc: 0.4598\n",
            "Epoch 3/10 | Train Loss: 0.1227, Train Acc: 0.9635 | Val Loss: 2.5113, Val Acc: 0.3784\n",
            "Epoch 4/10 | Train Loss: 0.1073, Train Acc: 0.9683 | Val Loss: 2.3734, Val Acc: 0.4478\n",
            "Epoch 5/10 | Train Loss: 0.0947, Train Acc: 0.9721 | Val Loss: 2.5753, Val Acc: 0.4946\n",
            "Epoch 6/10 | Train Loss: 0.0895, Train Acc: 0.9729 | Val Loss: 2.6204, Val Acc: 0.4596\n",
            "Epoch 7/10 | Train Loss: 0.0827, Train Acc: 0.9747 | Val Loss: 2.7524, Val Acc: 0.4211\n",
            "Epoch 8/10 | Train Loss: 0.0788, Train Acc: 0.9763 | Val Loss: 2.5320, Val Acc: 0.4123\n",
            "Epoch 9/10 | Train Loss: 0.0779, Train Acc: 0.9766 | Val Loss: 2.1406, Val Acc: 0.5864\n",
            "Epoch 10/10 | Train Loss: 0.0739, Train Acc: 0.9779 | Val Loss: 2.4603, Val Acc: 0.5245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns194RJv2lFg",
        "outputId": "d44ba6b7-a625-4d66-b7ae-11b227a99b0e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.3308, Test Acc: 0.3481\n"
          ]
        }
      ]
    }
  ]
}
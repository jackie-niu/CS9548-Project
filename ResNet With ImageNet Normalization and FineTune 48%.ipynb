{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crime Classification – CS 9548 Project\n",
        "**Goal:** Exploring Machine Learning Techniques for Image Classification"
      ],
      "metadata": {
        "id": "uuKIFcxpbk7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKK32z3dbeIh",
        "outputId": "2759806e-93ad-43d3-f9a7-d8d8fc4c5cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Extract Dataset"
      ],
      "metadata": {
        "id": "LSayQtOQrtBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiKxeSBbrGH",
        "outputId": "f485ea36-332b-4501-ad7e-c436e40c0bc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/odins0n/ucf-crime-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.0G/11.0G [08:39<00:00, 22.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataFrame of Images"
      ],
      "metadata": {
        "id": "EAAnRw4br3yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "# Get directories of train and test datasets\n",
        "data_dir = pathlib.Path(path)\n",
        "train_dir = data_dir / \"Train\"\n",
        "test_dir = data_dir / \"Test\"\n",
        "\n",
        "print(\"Data dir:\", data_dir)\n",
        "print(train_dir)\n",
        "print(test_dir)\n",
        "\n",
        "# Function to build dataframe\n",
        "def build_image_df(root_dir):\n",
        "    root_dir = pathlib.Path(root_dir)\n",
        "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for p in image_paths:\n",
        "        label = p.parent.name\n",
        "        rows.append({\"image\": str(p), \"label\": label})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Build train and test dataframes\n",
        "train_df = build_image_df(train_dir)\n",
        "test_df = build_image_df(test_dir)\n",
        "\n",
        "print(train_df['label'].value_counts())\n",
        "print(test_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79zyumijenlM",
        "outputId": "096376d2-b632-4a44-9d3e-3520aa4236da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dir: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Train\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Test\n",
            "label\n",
            "NormalVideos     947768\n",
            "Stealing          44802\n",
            "Robbery           41493\n",
            "Burglary          39504\n",
            "Arrest            26397\n",
            "Shoplifting       24835\n",
            "Fighting          24684\n",
            "Arson             24421\n",
            "RoadAccidents     23486\n",
            "Abuse             19076\n",
            "Explosion         18753\n",
            "Vandalism         13626\n",
            "Assault           10360\n",
            "Shooting           7140\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "NormalVideos     64952\n",
            "Burglary          7657\n",
            "Shooting          7630\n",
            "Shoplifting       7623\n",
            "Explosion         6510\n",
            "Arrest            3365\n",
            "Arson             2793\n",
            "RoadAccidents     2663\n",
            "Assault           2657\n",
            "Stealing          1984\n",
            "Fighting          1231\n",
            "Vandalism         1111\n",
            "Robbery            835\n",
            "Abuse              297\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Label as Integer"
      ],
      "metadata": {
        "id": "04OgKDsqxxW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit label encoder on training labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_idx'] = le.fit_transform(train_df['label'])\n",
        "\n",
        "# Apply the same encoding to test labels\n",
        "test_df['label_idx']  = le.transform(test_df['label'])\n",
        "\n",
        "# Number of classes and mapping\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class name vs label_idx:\")\n",
        "for index, cls in enumerate(le.classes_):\n",
        "    print(index, cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8URqILnwt2WI",
        "outputId": "dbd7027f-f775-4302-c4d8-953b349177bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 14\n",
            "Class name vs label_idx:\n",
            "0 Abuse\n",
            "1 Arrest\n",
            "2 Arson\n",
            "3 Assault\n",
            "4 Burglary\n",
            "5 Explosion\n",
            "6 Fighting\n",
            "7 NormalVideos\n",
            "8 RoadAccidents\n",
            "9 Robbery\n",
            "10 Shooting\n",
            "11 Shoplifting\n",
            "12 Stealing\n",
            "13 Vandalism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling, as well as data augmentation."
      ],
      "metadata": {
        "id": "3zpNQ1fvB7CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Video Column ID"
      ],
      "metadata": {
        "id": "1QqbjHTTIj2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_id(path_str):\n",
        "    stem = pathlib.Path(path_str).stem\n",
        "\n",
        "    # split off the last chunk\n",
        "    video_id = stem.rsplit(\"_\", 1)[0]\n",
        "\n",
        "    return video_id\n",
        "\n",
        "train_df['video_id'] = train_df['image'].apply(extract_video_id)\n",
        "test_df['video_id']  = test_df['image'].apply(extract_video_id)"
      ],
      "metadata": {
        "id": "WwouvCRwIjAJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train Into Train and Val"
      ],
      "metadata": {
        "id": "e2iqmT3H-ZHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "unique_videos = train_df['video_id'].unique()\n",
        "\n",
        "video_labels = (\n",
        "    train_df.groupby('video_id')['label_idx'].agg(lambda x: np.bincount(x).argmax()).reindex(unique_videos)\n",
        ")\n",
        "\n",
        "# 80% train 20% val\n",
        "train_vids, val_vids = train_test_split(\n",
        "    unique_videos,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=video_labels\n",
        ")\n",
        "\n",
        "train_df_raw = train_df[train_df['video_id'].isin(train_vids)].reset_index(drop=True)\n",
        "val_df = train_df[train_df['video_id'].isin(val_vids)].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nNum train videos:\", len(train_vids))\n",
        "print(\"Num val videos:\", len(val_vids))\n",
        "print(\"Train frames:\", len(train_df_raw))\n",
        "print(\"Val frames:\", len(val_df))\n",
        "print(\"Test frames:\", len(test_df))"
      ],
      "metadata": {
        "id": "LmdPhvLV-a0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262329c3-66f3-4026-8e3a-dd18b3ba68e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Num train videos: 1288\n",
            "Num val videos: 322\n",
            "Train frames: 1048730\n",
            "Val frames: 217615\n",
            "Test frames: 111308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Over/undersampling"
      ],
      "metadata": {
        "id": "C3sNtMlKU9Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_used = train_df_raw\n",
        "\n",
        "# Compute class counts (sorted by label index)\n",
        "class_counts = train_df_used['label_idx'].value_counts().sort_index().values\n",
        "num_classes = len(class_counts)\n",
        "\n",
        "# Inverse-frequency style weights\n",
        "# weight_c = total_samples / (num_classes * count_c)\n",
        "\n",
        "class_weights = class_counts.sum() / (num_classes * class_counts)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n"
      ],
      "metadata": {
        "id": "-vgbAuEsbusr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a3bf9d-bd14-402c-9750-5335061d864a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: [ 4.71602151  3.4909724   3.38481251  7.95046548  2.19849399  4.12791567\n",
            "  3.5513813   0.09588094  4.00220579  2.2813158  11.73942732  3.15846379\n",
            "  2.21376221  7.6759182 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df_used['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpXWJOjHsvlW",
        "outputId": "b2e4ddbc-d040-4ed4-b30b-6956d7d108ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "NormalVideos     797939\n",
            "Stealing          35375\n",
            "Burglary          32791\n",
            "Robbery           32158\n",
            "Arrest            22066\n",
            "Fighting          21190\n",
            "Shoplifting       20627\n",
            "Explosion         18041\n",
            "RoadAccidents     17624\n",
            "Abuse             14582\n",
            "Arson             10315\n",
            "Vandalism          9669\n",
            "Assault            8955\n",
            "Shooting           5807\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up PyTorch"
      ],
      "metadata": {
        "id": "PfhjEsJsKTz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Set constants for PyTorch\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "AXeau7INGq3K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "mqf9D2jzPiiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation to training dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(contrast=0.1, brightness=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n",
        "# Simple transforms to val/test dataset\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])"
      ],
      "metadata": {
        "id": "P6VHgGIaPkQs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Pipeline For PyTorch"
      ],
      "metadata": {
        "id": "r9SfD-Yoe5WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrimeDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image']\n",
        "        label = int(row['label_idx'])\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Transform if needed (might not need for val/test)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "x7MPkUfJe4Ms"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataLoaders"
      ],
      "metadata": {
        "id": "ZrSFo_31fsiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert to CrimeDataset classes\n",
        "train_dataset = CrimeDataset(train_df_used, train_transform)\n",
        "val_dataset = CrimeDataset(val_df, eval_transform)\n",
        "test_dataset = CrimeDataset(test_df, eval_transform)\n",
        "\n",
        "# Transform to DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "pMXciaJZN6tv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"\\nSample batch shapes -> images:\", images.shape, \"labels:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzyFAt9lKxkF",
        "outputId": "15b20692-437f-4f69-eba3-81dbfc51d983"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample batch shapes -> images: torch.Size([32, 3, 224, 224]) labels: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ResNet18 Model"
      ],
      "metadata": {
        "id": "rsl42desQDEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Freeze all layers initially (warmup)\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace final fully-connected layer\n",
        "num_features = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "model = resnet.to(device)\n",
        "\n",
        "# Move class weights to same device\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Class-weighted loss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Add L2 regularization via weight_decay\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "j7CB06lIQI-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71afd89-cafd-494c-b068-20922aec9dd5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 237MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing"
      ],
      "metadata": {
        "id": "Oald1KXZTIsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "oLnKSq4dTKlR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "ZDvgQ4BRG1CD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WARMUP_EPOCHS = 3\n",
        "\n",
        "for epoch in range(1, WARMUP_EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
        "\n",
        "    print(\n",
        "        f\"[Warmup] Epoch {epoch}/{WARMUP_EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKnxWZ3IJEPx",
        "outputId": "5bdf6133-ad89-4b36-ff96-f7a9a2a239dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Warmup] Epoch 1/3 | Train Loss: 1.1290, Train Acc: 0.6505 | Val Loss: 2.5782, Val Acc: 0.2908\n",
            "[Warmup] Epoch 2/3 | Train Loss: 0.9963, Train Acc: 0.6747 | Val Loss: 2.2255, Val Acc: 0.3598\n",
            "[Warmup] Epoch 3/3 | Train Loss: 0.9833, Train Acc: 0.6774 | Val Loss: 2.4533, Val Acc: 0.3180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "C160z8HFJLc5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H06Mj3Mfh4xo",
        "outputId": "9b9ffad9-2d77-4836-c7db-244b7b084357"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.1395, Train Acc: 0.9463 | Val Loss: 2.7129, Val Acc: 0.5347\n",
            "Epoch 2/5 | Train Loss: 0.0463, Train Acc: 0.9803 | Val Loss: 2.3946, Val Acc: 0.6255\n",
            "Epoch 3/5 | Train Loss: 0.0371, Train Acc: 0.9839 | Val Loss: 2.5747, Val Acc: 0.5880\n",
            "Epoch 4/5 | Train Loss: 0.0313, Train Acc: 0.9867 | Val Loss: 2.4157, Val Acc: 0.5357\n",
            "Epoch 5/5 | Train Loss: 0.0280, Train Acc: 0.9881 | Val Loss: 2.5599, Val Acc: 0.5982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns194RJv2lFg",
        "outputId": "13212913-fe9f-42f6-af1c-480ad3a6155e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.7351, Test Acc: 0.4762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rhlV8DO9GvH",
        "outputId": "7edb4959-bea6-4623-e92e-18189e95cca8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ]
    }
  ]
}
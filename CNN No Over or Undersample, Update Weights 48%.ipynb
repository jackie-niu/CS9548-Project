{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crime Classification – CS 9548 Project\n",
        "**Goal:** Exploring Machine Learning Techniques for Image Classification"
      ],
      "metadata": {
        "id": "uuKIFcxpbk7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKK32z3dbeIh",
        "outputId": "63b1102c-4d97-4bbf-b708-3337c0b9d075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Extract Dataset"
      ],
      "metadata": {
        "id": "LSayQtOQrtBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiKxeSBbrGH",
        "outputId": "b4a5c28c-1541-4484-f729-1c32c33852b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/odins0n/ucf-crime-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.0G/11.0G [04:52<00:00, 40.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataFrame of Images"
      ],
      "metadata": {
        "id": "EAAnRw4br3yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "# Get directories of train and test datasets\n",
        "data_dir = pathlib.Path(path)\n",
        "train_dir = data_dir / \"Train\"\n",
        "test_dir = data_dir / \"Test\"\n",
        "\n",
        "print(\"Data dir:\", data_dir)\n",
        "print(train_dir)\n",
        "print(test_dir)\n",
        "\n",
        "# Function to build dataframe\n",
        "def build_image_df(root_dir):\n",
        "    root_dir = pathlib.Path(root_dir)\n",
        "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for p in image_paths:\n",
        "        label = p.parent.name\n",
        "        rows.append({\"image\": str(p), \"label\": label})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Build train and test dataframes\n",
        "train_df = build_image_df(train_dir)\n",
        "test_df = build_image_df(test_dir)\n",
        "\n",
        "print(train_df['label'].value_counts())\n",
        "print(test_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79zyumijenlM",
        "outputId": "db826f9b-737c-4f28-e64f-ede1e3ad15c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dir: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Train\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Test\n",
            "label\n",
            "NormalVideos     947768\n",
            "Stealing          44802\n",
            "Robbery           41493\n",
            "Burglary          39504\n",
            "Arrest            26397\n",
            "Shoplifting       24835\n",
            "Fighting          24684\n",
            "Arson             24421\n",
            "RoadAccidents     23486\n",
            "Abuse             19076\n",
            "Explosion         18753\n",
            "Vandalism         13626\n",
            "Assault           10360\n",
            "Shooting           7140\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "NormalVideos     64952\n",
            "Burglary          7657\n",
            "Shooting          7630\n",
            "Shoplifting       7623\n",
            "Explosion         6510\n",
            "Arrest            3365\n",
            "Arson             2793\n",
            "RoadAccidents     2663\n",
            "Assault           2657\n",
            "Stealing          1984\n",
            "Fighting          1231\n",
            "Vandalism         1111\n",
            "Robbery            835\n",
            "Abuse              297\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Label as Integer"
      ],
      "metadata": {
        "id": "04OgKDsqxxW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit label encoder on training labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_idx'] = le.fit_transform(train_df['label'])\n",
        "\n",
        "# Apply the same encoding to test labels\n",
        "test_df['label_idx']  = le.transform(test_df['label'])\n",
        "\n",
        "# Number of classes and mapping\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class name vs label_idx:\")\n",
        "for index, cls in enumerate(le.classes_):\n",
        "    print(index, cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8URqILnwt2WI",
        "outputId": "9dd7917c-3c43-4d2a-b766-a5729982e88e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 14\n",
            "Class name vs label_idx:\n",
            "0 Abuse\n",
            "1 Arrest\n",
            "2 Arson\n",
            "3 Assault\n",
            "4 Burglary\n",
            "5 Explosion\n",
            "6 Fighting\n",
            "7 NormalVideos\n",
            "8 RoadAccidents\n",
            "9 Robbery\n",
            "10 Shooting\n",
            "11 Shoplifting\n",
            "12 Stealing\n",
            "13 Vandalism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling, as well as data augmentation."
      ],
      "metadata": {
        "id": "3zpNQ1fvB7CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Video Column ID"
      ],
      "metadata": {
        "id": "1QqbjHTTIj2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_id(path_str):\n",
        "    stem = pathlib.Path(path_str).stem\n",
        "\n",
        "    # split off the last chunk\n",
        "    video_id = stem.rsplit(\"_\", 1)[0]\n",
        "\n",
        "    return video_id\n",
        "\n",
        "train_df['video_id'] = train_df['image'].apply(extract_video_id)\n",
        "test_df['video_id']  = test_df['image'].apply(extract_video_id)"
      ],
      "metadata": {
        "id": "WwouvCRwIjAJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train Into Train and Val"
      ],
      "metadata": {
        "id": "e2iqmT3H-ZHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "unique_videos = train_df['video_id'].unique()\n",
        "\n",
        "video_labels = (\n",
        "    train_df.groupby('video_id')['label_idx'].agg(lambda x: np.bincount(x).argmax()).reindex(unique_videos)\n",
        ")\n",
        "\n",
        "# 80% train 20% val\n",
        "train_vids, val_vids = train_test_split(\n",
        "    unique_videos,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=video_labels\n",
        ")\n",
        "\n",
        "train_df_raw = train_df[train_df['video_id'].isin(train_vids)].reset_index(drop=True)\n",
        "val_df = train_df[train_df['video_id'].isin(val_vids)].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nNum train videos:\", len(train_vids))\n",
        "print(\"Num val videos:\", len(val_vids))\n",
        "print(\"Train frames:\", len(train_df_raw))\n",
        "print(\"Val frames:\", len(val_df))\n",
        "print(\"Test frames:\", len(test_df))"
      ],
      "metadata": {
        "id": "LmdPhvLV-a0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787dda9c-72c0-4175-b2dd-d609d687112f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Num train videos: 1288\n",
            "Num val videos: 322\n",
            "Train frames: 883856\n",
            "Val frames: 382489\n",
            "Test frames: 111308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Over/undersampling"
      ],
      "metadata": {
        "id": "C3sNtMlKU9Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_used = train_df_raw\n",
        "\n",
        "print(\"\\nTrain label counts (unbalanced):\")\n",
        "print(train_df_used['label'].value_counts())\n",
        "print(\"\\nVal label counts:\")\n",
        "print(val_df['label'].value_counts())\n",
        "print(\"\\nTest label counts:\")\n",
        "print(test_df['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgbAuEsbusr",
        "outputId": "81311421-4fec-4f17-fa88-79525ec8ee80"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train label counts (unbalanced):\n",
            "label\n",
            "NormalVideos     625905\n",
            "Robbery           34936\n",
            "Stealing          32803\n",
            "Burglary          28297\n",
            "Shoplifting       22300\n",
            "Arrest            22250\n",
            "Arson             21754\n",
            "Fighting          20078\n",
            "RoadAccidents     18275\n",
            "Explosion         18146\n",
            "Abuse             14442\n",
            "Vandalism         10055\n",
            "Assault            8419\n",
            "Shooting           6196\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Val label counts:\n",
            "label\n",
            "NormalVideos     321863\n",
            "Stealing          11999\n",
            "Burglary          11207\n",
            "Robbery            6557\n",
            "RoadAccidents      5211\n",
            "Abuse              4634\n",
            "Fighting           4606\n",
            "Arrest             4147\n",
            "Vandalism          3571\n",
            "Arson              2667\n",
            "Shoplifting        2535\n",
            "Assault            1941\n",
            "Shooting            944\n",
            "Explosion           607\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test label counts:\n",
            "label\n",
            "NormalVideos     64952\n",
            "Burglary          7657\n",
            "Shooting          7630\n",
            "Shoplifting       7623\n",
            "Explosion         6510\n",
            "Arrest            3365\n",
            "Arson             2793\n",
            "RoadAccidents     2663\n",
            "Assault           2657\n",
            "Stealing          1984\n",
            "Fighting          1231\n",
            "Vandalism         1111\n",
            "Robbery            835\n",
            "Abuse              297\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class counts (sorted by label index)\n",
        "class_counts = train_df_used['label_idx'].value_counts().sort_index().values\n",
        "num_classes = len(class_counts)\n",
        "\n",
        "# Inverse-frequency style weights\n",
        "# weight_c = total_samples / (num_classes * count_c)\n",
        "\n",
        "class_weights = class_counts.sum() / (num_classes * class_counts)\n",
        "print(\"Class weights:\", class_weights)"
      ],
      "metadata": {
        "id": "jLVIQV3YCUpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1039f50-5808-41fd-f286-ef3c1e84bebd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: [ 4.37145627  2.83741894  2.90211324  7.49882069  2.23106942  3.47914534\n",
            "  3.14436555  0.10086606  3.45458667  1.80709215 10.18924652  2.83105701\n",
            "  1.92459749  6.27872416]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up PyTorch"
      ],
      "metadata": {
        "id": "PfhjEsJsKTz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Set constants for PyTorch\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "AXeau7INGq3K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "mqf9D2jzPiiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation to training dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)),\n",
        "    transforms.ColorJitter(contrast=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Simple transforms to val/test dataset\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "P6VHgGIaPkQs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Pipeline For PyTorch"
      ],
      "metadata": {
        "id": "r9SfD-Yoe5WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrimeDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image']\n",
        "        label = int(row['label_idx'])\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Transform if needed (might not need for val/test)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "x7MPkUfJe4Ms"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataLoaders"
      ],
      "metadata": {
        "id": "ZrSFo_31fsiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert to CrimeDataset classes\n",
        "train_dataset = CrimeDataset(train_df_used, train_transform)\n",
        "val_dataset = CrimeDataset(val_df, eval_transform)\n",
        "test_dataset = CrimeDataset(test_df, eval_transform)\n",
        "\n",
        "# Transform to DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "pMXciaJZN6tv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"\\nSample batch shapes -> images:\", images.shape, \"labels:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzyFAt9lKxkF",
        "outputId": "a307c502-dc06-40df-cfd8-bc20307a7c4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample batch shapes -> images: torch.Size([32, 3, 64, 64]) labels: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create CNN Model"
      ],
      "metadata": {
        "id": "rsl42desQDEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten_dim = 128 * 8 * 8\n",
        "\n",
        "        self.fc1 = nn.Linear(self.flatten_dim, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "model = Net(num_classes=num_classes).to(device)\n",
        "\n",
        "# Move class weights to same device\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Class-weighted loss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Add L2 regularization via weight_decay\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "j7CB06lIQI-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4b2c41-ddcc-40c2-9dbc-66374d88e2fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing"
      ],
      "metadata": {
        "id": "Oald1KXZTIsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "oLnKSq4dTKlR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "ZDvgQ4BRG1CD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H06Mj3Mfh4xo",
        "outputId": "e214a742-e5a3-4f7e-e812-5bd3a0d5a6c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7112, Train Acc: 0.6996 | Val Loss: 1.6973, Val Acc: 0.5628\n",
            "Epoch 2/10 | Train Loss: 0.3005, Train Acc: 0.8547 | Val Loss: 1.6444, Val Acc: 0.5499\n",
            "Epoch 3/10 | Train Loss: 0.2643, Train Acc: 0.8698 | Val Loss: 1.7042, Val Acc: 0.5943\n",
            "Epoch 4/10 | Train Loss: 0.2490, Train Acc: 0.8797 | Val Loss: 1.5557, Val Acc: 0.6285\n",
            "Epoch 5/10 | Train Loss: 0.2429, Train Acc: 0.8872 | Val Loss: 1.4687, Val Acc: 0.6129\n",
            "Epoch 6/10 | Train Loss: 0.2343, Train Acc: 0.8944 | Val Loss: 1.8157, Val Acc: 0.6669\n",
            "Epoch 7/10 | Train Loss: 0.2313, Train Acc: 0.8990 | Val Loss: 1.9775, Val Acc: 0.5599\n",
            "Epoch 8/10 | Train Loss: 0.2285, Train Acc: 0.9039 | Val Loss: 1.9020, Val Acc: 0.5519\n",
            "Epoch 9/10 | Train Loss: 0.2255, Train Acc: 0.9059 | Val Loss: 1.3952, Val Acc: 0.6643\n",
            "Epoch 10/10 | Train Loss: 0.2239, Train Acc: 0.9099 | Val Loss: 1.4501, Val Acc: 0.6530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns194RJv2lFg",
        "outputId": "6d0c0807-c477-4b2f-87e8-c76699e6a29a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.1888, Test Acc: 0.4805\n"
          ]
        }
      ]
    }
  ]
}
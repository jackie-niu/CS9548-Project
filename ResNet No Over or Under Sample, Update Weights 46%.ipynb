{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crime Classification – CS 9548 Project\n",
        "**Goal:** Exploring Machine Learning Techniques for Image Classification"
      ],
      "metadata": {
        "id": "uuKIFcxpbk7H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKK32z3dbeIh",
        "outputId": "c253a431-028b-4a1b-f5a6-b43f5cc62871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Extract Dataset"
      ],
      "metadata": {
        "id": "LSayQtOQrtBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub\n",
        "\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIiKxeSBbrGH",
        "outputId": "d60ef426-803f-4e30-ef4b-355e0726c3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/odins0n/ucf-crime-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.0G/11.0G [08:24<00:00, 23.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataFrame of Images"
      ],
      "metadata": {
        "id": "EAAnRw4br3yB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import pandas as pd\n",
        "\n",
        "# Get directories of train and test datasets\n",
        "data_dir = pathlib.Path(path)\n",
        "train_dir = data_dir / \"Train\"\n",
        "test_dir = data_dir / \"Test\"\n",
        "\n",
        "print(\"Data dir:\", data_dir)\n",
        "print(train_dir)\n",
        "print(test_dir)\n",
        "\n",
        "# Function to build dataframe\n",
        "def build_image_df(root_dir):\n",
        "    root_dir = pathlib.Path(root_dir)\n",
        "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for p in image_paths:\n",
        "        label = p.parent.name\n",
        "        rows.append({\"image\": str(p), \"label\": label})\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# Build train and test dataframes\n",
        "train_df = build_image_df(train_dir)\n",
        "test_df = build_image_df(test_dir)\n",
        "\n",
        "print(train_df['label'].value_counts())\n",
        "print(test_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79zyumijenlM",
        "outputId": "eadabd00-d54c-40db-a5d0-112be177b28a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dir: /root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Train\n",
            "/root/.cache/kagglehub/datasets/odins0n/ucf-crime-dataset/versions/1/Test\n",
            "label\n",
            "NormalVideos     947768\n",
            "Stealing          44802\n",
            "Robbery           41493\n",
            "Burglary          39504\n",
            "Arrest            26397\n",
            "Shoplifting       24835\n",
            "Fighting          24684\n",
            "Arson             24421\n",
            "RoadAccidents     23486\n",
            "Abuse             19076\n",
            "Explosion         18753\n",
            "Vandalism         13626\n",
            "Assault           10360\n",
            "Shooting           7140\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "NormalVideos     64952\n",
            "Burglary          7657\n",
            "Shooting          7630\n",
            "Shoplifting       7623\n",
            "Explosion         6510\n",
            "Arrest            3365\n",
            "Arson             2793\n",
            "RoadAccidents     2663\n",
            "Assault           2657\n",
            "Stealing          1984\n",
            "Fighting          1231\n",
            "Vandalism         1111\n",
            "Robbery            835\n",
            "Abuse              297\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Label as Integer"
      ],
      "metadata": {
        "id": "04OgKDsqxxW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create and fit label encoder on training labels\n",
        "le = LabelEncoder()\n",
        "train_df['label_idx'] = le.fit_transform(train_df['label'])\n",
        "\n",
        "# Apply the same encoding to test labels\n",
        "test_df['label_idx']  = le.transform(test_df['label'])\n",
        "\n",
        "# Number of classes and mapping\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class name vs label_idx:\")\n",
        "for index, cls in enumerate(le.classes_):\n",
        "    print(index, cls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8URqILnwt2WI",
        "outputId": "478b55af-e947-43e5-8185-3d2b742ad37b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 14\n",
            "Class name vs label_idx:\n",
            "0 Abuse\n",
            "1 Arrest\n",
            "2 Arson\n",
            "3 Assault\n",
            "4 Burglary\n",
            "5 Explosion\n",
            "6 Fighting\n",
            "7 NormalVideos\n",
            "8 RoadAccidents\n",
            "9 Robbery\n",
            "10 Shooting\n",
            "11 Shoplifting\n",
            "12 Stealing\n",
            "13 Vandalism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling, as well as data augmentation."
      ],
      "metadata": {
        "id": "3zpNQ1fvB7CT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Video Column ID"
      ],
      "metadata": {
        "id": "1QqbjHTTIj2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_id(path_str):\n",
        "    stem = pathlib.Path(path_str).stem\n",
        "\n",
        "    # split off the last chunk\n",
        "    video_id = stem.rsplit(\"_\", 1)[0]\n",
        "\n",
        "    return video_id\n",
        "\n",
        "train_df['video_id'] = train_df['image'].apply(extract_video_id)\n",
        "test_df['video_id']  = test_df['image'].apply(extract_video_id)"
      ],
      "metadata": {
        "id": "WwouvCRwIjAJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Train Into Train and Val"
      ],
      "metadata": {
        "id": "e2iqmT3H-ZHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "unique_videos = train_df['video_id'].unique()\n",
        "\n",
        "video_labels = (\n",
        "    train_df.groupby('video_id')['label_idx'].agg(lambda x: np.bincount(x).argmax()).reindex(unique_videos)\n",
        ")\n",
        "\n",
        "# 80% train 20% val\n",
        "train_vids, val_vids = train_test_split(\n",
        "    unique_videos,\n",
        "    test_size=0.20,\n",
        "    random_state=42,\n",
        "    stratify=video_labels\n",
        ")\n",
        "\n",
        "train_df_raw = train_df[train_df['video_id'].isin(train_vids)].reset_index(drop=True)\n",
        "val_df = train_df[train_df['video_id'].isin(val_vids)].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nNum train videos:\", len(train_vids))\n",
        "print(\"Num val videos:\", len(val_vids))\n",
        "print(\"Train frames:\", len(train_df_raw))\n",
        "print(\"Val frames:\", len(val_df))\n",
        "print(\"Test frames:\", len(test_df))"
      ],
      "metadata": {
        "id": "LmdPhvLV-a0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30010b2-4cfc-42a6-c523-530a3e38935e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Num train videos: 1288\n",
            "Num val videos: 322\n",
            "Train frames: 1047139\n",
            "Val frames: 219206\n",
            "Test frames: 111308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# No Over/undersampling"
      ],
      "metadata": {
        "id": "C3sNtMlKU9Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_used = train_df_raw\n",
        "\n",
        "# Compute class counts (sorted by label index)\n",
        "class_counts = train_df_used['label_idx'].value_counts().sort_index().values\n",
        "num_classes = len(class_counts)\n",
        "\n",
        "# Inverse-frequency style weights\n",
        "# weight_c = total_samples / (num_classes * count_c)\n",
        "\n",
        "class_weights = class_counts.sum() / (num_classes * class_counts)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n"
      ],
      "metadata": {
        "id": "-vgbAuEsbusr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ec2c94-2bef-4f5a-a871-d4ff87f92cc3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: [ 5.12931305  3.38963305  7.25115297  8.35238893  2.28098084  4.14587012\n",
            "  3.52976134  0.09373604  4.24396521  2.32587981 12.88025536  3.62610379\n",
            "  2.11436446  7.73561308]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df_used['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpXWJOjHsvlW",
        "outputId": "b2e4ddbc-d040-4ed4-b30b-6956d7d108ec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "NormalVideos     797939\n",
            "Stealing          35375\n",
            "Burglary          32791\n",
            "Robbery           32158\n",
            "Arrest            22066\n",
            "Fighting          21190\n",
            "Shoplifting       20627\n",
            "Explosion         18041\n",
            "RoadAccidents     17624\n",
            "Abuse             14582\n",
            "Arson             10315\n",
            "Vandalism          9669\n",
            "Assault            8955\n",
            "Shooting           5807\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up PyTorch"
      ],
      "metadata": {
        "id": "PfhjEsJsKTz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Set constants for PyTorch\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "AXeau7INGq3K"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "mqf9D2jzPiiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation to training dataset\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)),\n",
        "    transforms.ColorJitter(contrast=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Simple transforms to val/test dataset\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "P6VHgGIaPkQs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Pipeline For PyTorch"
      ],
      "metadata": {
        "id": "r9SfD-Yoe5WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrimeDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image']\n",
        "        label = int(row['label_idx'])\n",
        "\n",
        "        # Load the image\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Transform if needed (might not need for val/test)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "x7MPkUfJe4Ms"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create DataLoaders"
      ],
      "metadata": {
        "id": "ZrSFo_31fsiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert to CrimeDataset classes\n",
        "train_dataset = CrimeDataset(train_df_used, train_transform)\n",
        "val_dataset = CrimeDataset(val_df, eval_transform)\n",
        "test_dataset = CrimeDataset(test_df, eval_transform)\n",
        "\n",
        "# Transform to DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "pMXciaJZN6tv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"\\nSample batch shapes -> images:\", images.shape, \"labels:\", labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzyFAt9lKxkF",
        "outputId": "c47f078d-628e-4ab8-f4af-f98b0576309c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample batch shapes -> images: torch.Size([32, 3, 224, 224]) labels: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ResNet18 Model"
      ],
      "metadata": {
        "id": "rsl42desQDEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Move class weights to same device\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "# Class-weighted loss\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "# Add L2 regularization via weight_decay\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "j7CB06lIQI-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919124b1-4341-4012-e005-91efb079f81b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing"
      ],
      "metadata": {
        "id": "Oald1KXZTIsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "oLnKSq4dTKlR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "ZDvgQ4BRG1CD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H06Mj3Mfh4xo",
        "outputId": "d4e19140-4576-4e0b-fe94-ebcbe2d7e417"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.5465, Train Acc: 0.8152 | Val Loss: 2.8190, Val Acc: 0.3609\n",
            "Epoch 2/10 | Train Loss: 0.1849, Train Acc: 0.9194 | Val Loss: 2.7386, Val Acc: 0.3583\n",
            "Epoch 3/10 | Train Loss: 0.1518, Train Acc: 0.9314 | Val Loss: 2.3686, Val Acc: 0.5070\n",
            "Epoch 4/10 | Train Loss: 0.1392, Train Acc: 0.9378 | Val Loss: 2.7792, Val Acc: 0.4467\n",
            "Epoch 5/10 | Train Loss: 0.1307, Train Acc: 0.9408 | Val Loss: 2.4532, Val Acc: 0.4441\n",
            "Epoch 6/10 | Train Loss: 0.1264, Train Acc: 0.9425 | Val Loss: 2.5276, Val Acc: 0.4784\n",
            "Epoch 7/10 | Train Loss: 0.1218, Train Acc: 0.9451 | Val Loss: 2.6224, Val Acc: 0.4469\n",
            "Epoch 8/10 | Train Loss: 0.1191, Train Acc: 0.9455 | Val Loss: 2.6254, Val Acc: 0.4016\n",
            "Epoch 9/10 | Train Loss: 0.1155, Train Acc: 0.9467 | Val Loss: 2.6037, Val Acc: 0.4247\n",
            "Epoch 10/10 | Train Loss: 0.1146, Train Acc: 0.9468 | Val Loss: 2.6309, Val Acc: 0.4016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns194RJv2lFg",
        "outputId": "4944cb96-62da-45ad-d6d5-a3c966e290b1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.2868, Test Acc: 0.4576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rhlV8DO9GvH",
        "outputId": "70f99f04-ab7d-4652-dcd2-9b5bb49ccef0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ]
    }
  ]
}
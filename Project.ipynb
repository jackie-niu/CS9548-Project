{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed12c57d",
   "metadata": {},
   "source": [
    "# Crime Classification â€“ CS 9548 Project\n",
    "**Goal:** Exploring Machine Learning Techniques for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b771e8",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65678ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 1)) (0.3.13)\n",
      "Requirement already satisfied: numpy in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 7)) (2.20.0)\n",
      "Requirement already satisfied: torch in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 8)) (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 9)) (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 10)) (2.8.0)\n",
      "Requirement already satisfied: pathlib in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 11)) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (6.33.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from torch->-r requirements.txt (line 8)) (2025.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 7)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (0.18.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tqdm->kagglehub->-r requirements.txt (line 1)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce415497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf81b5",
   "metadata": {},
   "source": [
    "## Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e1e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda1ea8",
   "metadata": {},
   "source": [
    "## Create DataFrame of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23a855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\n",
      "C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\\Train\n",
      "C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\\Test\n",
      "label\n",
      "NormalVideos     947768\n",
      "Stealing          44802\n",
      "Robbery           41493\n",
      "Burglary          39504\n",
      "Arrest            26397\n",
      "Shoplifting       24835\n",
      "Fighting          24684\n",
      "Arson             24421\n",
      "RoadAccidents     23486\n",
      "Abuse             19076\n",
      "Explosion         18753\n",
      "Vandalism         13626\n",
      "Assault           10360\n",
      "Shooting           7140\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "NormalVideos     64952\n",
      "Burglary          7657\n",
      "Shooting          7630\n",
      "Shoplifting       7623\n",
      "Explosion         6510\n",
      "Arrest            3365\n",
      "Arson             2793\n",
      "RoadAccidents     2663\n",
      "Assault           2657\n",
      "Stealing          1984\n",
      "Fighting          1231\n",
      "Vandalism         1111\n",
      "Robbery            835\n",
      "Abuse              297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# Get directories of train and test datasets\n",
    "data_dir = pathlib.Path(path)\n",
    "train_dir = data_dir / \"Train\"\n",
    "test_dir = data_dir / \"Test\"\n",
    "\n",
    "print(\"Data dir:\", data_dir)\n",
    "print(train_dir)\n",
    "print(test_dir)\n",
    "\n",
    "# Function to build dataframe\n",
    "def build_image_df(root_dir):\n",
    "    root_dir = pathlib.Path(root_dir)\n",
    "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for p in image_paths:\n",
    "        label = p.parent.name \n",
    "        rows.append({\"image\": str(p), \"label\": label})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Build train and test dataframes\n",
    "train = build_image_df(train_dir)\n",
    "test = build_image_df(test_dir)\n",
    "\n",
    "print(train['label'].value_counts())\n",
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c42d6",
   "metadata": {},
   "source": [
    "## Encode Label as Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3422e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 14\n",
      "Class name vs label_idx:\n",
      "0 Abuse\n",
      "1 Arrest\n",
      "2 Arson\n",
      "3 Assault\n",
      "4 Burglary\n",
      "5 Explosion\n",
      "6 Fighting\n",
      "7 NormalVideos\n",
      "8 RoadAccidents\n",
      "9 Robbery\n",
      "10 Shooting\n",
      "11 Shoplifting\n",
      "12 Stealing\n",
      "13 Vandalism\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create and fit label encoder on training labels\n",
    "le = LabelEncoder()\n",
    "train['label_idx'] = le.fit_transform(train['label'])\n",
    "\n",
    "# Apply the same encoding to test labels\n",
    "test['label_idx'] = le.transform(test['label'])\n",
    "\n",
    "# Number of classes and mapping\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Class name vs label_idx:\")\n",
    "for index, cls in enumerate(le.classes_):\n",
    "    print(index, cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5971e0e",
   "metadata": {},
   "source": [
    "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc906b90",
   "metadata": {},
   "source": [
    "## Under/Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize sizes for over/undersampling\n",
    "TARGET_NORMAL = 45000   # maximum size for NormalVideos undersampling\n",
    "TARGET_OTHER  = 40000   # minimum size for other classes oversampling\n",
    "\n",
    "# Undersample NormalVideos to 50,000\n",
    "normal_mask = train['label'] == \"NormalVideos\"\n",
    "\n",
    "normal_df = train[normal_mask].sample(n=TARGET_NORMAL, random_state=42)\n",
    "\n",
    "# Oversample all other classes\n",
    "\n",
    "# Create balanced_dfs as a list\n",
    "balanced_dfs = [normal_df]\n",
    "\n",
    "for cls in train['label'].unique():\n",
    "    if cls == \"NormalVideos\":\n",
    "        continue\n",
    "    \n",
    "    # Check number of samples for each class\n",
    "    cls_df = train[train['label'] == cls]\n",
    "    n_current = len(cls_df)\n",
    "    \n",
    "    # If there's enough samples, leave as it is\n",
    "    if n_current >= TARGET_OTHER:\n",
    "        balanced_dfs.append(cls_df)\n",
    "\n",
    "    else:\n",
    "        # Oversample with replacement\n",
    "        extra = cls_df.sample(\n",
    "            n=TARGET_OTHER - n_current,\n",
    "            replace=True,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        cls_balanced = pd.concat([cls_df, extra], ignore_index=True)\n",
    "        balanced_dfs.append(cls_balanced)\n",
    "\n",
    "# Put into new balanced training dataframe\n",
    "train_balanced = pd.concat(balanced_dfs).reset_index(drop=True)\n",
    "\n",
    "# Encode labels again\n",
    "train_balanced['label_idx'] = le.transform(train_balanced['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ed6baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "NormalVideos     45000\n",
      "Stealing         44802\n",
      "Robbery          41493\n",
      "Arson            40000\n",
      "Arrest           40000\n",
      "Abuse            40000\n",
      "Burglary         40000\n",
      "Assault          40000\n",
      "Fighting         40000\n",
      "Explosion        40000\n",
      "RoadAccidents    40000\n",
      "Shooting         40000\n",
      "Shoplifting      40000\n",
      "Vandalism        40000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_balanced['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599df956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...</td>\n",
       "      <td>NormalVideos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...</td>\n",
       "      <td>NormalVideos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...</td>\n",
       "      <td>NormalVideos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...</td>\n",
       "      <td>NormalVideos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...</td>\n",
       "      <td>NormalVideos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image         label  label_idx\n",
       "0  C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...  NormalVideos          7\n",
       "1  C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...  NormalVideos          7\n",
       "2  C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...  NormalVideos          7\n",
       "3  C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...  NormalVideos          7\n",
       "4  C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins...  NormalVideos          7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

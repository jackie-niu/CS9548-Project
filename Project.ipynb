{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed12c57d",
   "metadata": {},
   "source": [
    "# Crime Classification â€“ CS 9548 Project\n",
    "**Goal:** Exploring Machine Learning Techniques for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b771e8",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65678ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 1)) (0.3.13)\n",
      "Requirement already satisfied: numpy in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 4)) (3.10.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 5)) (1.7.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 7)) (2.20.0)\n",
      "Requirement already satisfied: pathlib in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from -r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from kagglehub->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (6.33.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorflow->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 7)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (0.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow->-r requirements.txt (line 7)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages (from tqdm->kagglehub->-r requirements.txt (line 1)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce415497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf81b5",
   "metadata": {},
   "source": [
    "## Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e1e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"odins0n/ucf-crime-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda1ea8",
   "metadata": {},
   "source": [
    "## Create DataFrame of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23a855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir: C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\n",
      "C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\\Train\n",
      "C:\\Users\\jacki\\.cache\\kagglehub\\datasets\\odins0n\\ucf-crime-dataset\\versions\\1\\Test\n",
      "label\n",
      "NormalVideos     947768\n",
      "Stealing          44802\n",
      "Robbery           41493\n",
      "Burglary          39504\n",
      "Arrest            26397\n",
      "Shoplifting       24835\n",
      "Fighting          24684\n",
      "Arson             24421\n",
      "RoadAccidents     23486\n",
      "Abuse             19076\n",
      "Explosion         18753\n",
      "Vandalism         13626\n",
      "Assault           10360\n",
      "Shooting           7140\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "NormalVideos     64952\n",
      "Burglary          7657\n",
      "Shooting          7630\n",
      "Shoplifting       7623\n",
      "Explosion         6510\n",
      "Arrest            3365\n",
      "Arson             2793\n",
      "RoadAccidents     2663\n",
      "Assault           2657\n",
      "Stealing          1984\n",
      "Fighting          1231\n",
      "Vandalism         1111\n",
      "Robbery            835\n",
      "Abuse              297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "# Get directories of train and test datasets\n",
    "data_dir = pathlib.Path(path)\n",
    "train_dir = data_dir / \"Train\"\n",
    "test_dir = data_dir / \"Test\"\n",
    "\n",
    "print(\"Data dir:\", data_dir)\n",
    "print(train_dir)\n",
    "print(test_dir)\n",
    "\n",
    "# Function to build dataframe\n",
    "def build_image_df(root_dir):\n",
    "    root_dir = pathlib.Path(root_dir)\n",
    "    image_paths = list(root_dir.glob(\"*/*.png\"))\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for p in image_paths:\n",
    "        label = p.parent.name\n",
    "        rows.append({\"image\": str(p), \"label\": label})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Build train and test dataframes\n",
    "train = build_image_df(train_dir)\n",
    "test = build_image_df(test_dir)\n",
    "\n",
    "print(train['label'].value_counts())\n",
    "print(test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c42d6",
   "metadata": {},
   "source": [
    "## Encode Label as Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3422e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 14\n",
      "Class name vs label_idx:\n",
      "0 Abuse\n",
      "1 Arrest\n",
      "2 Arson\n",
      "3 Assault\n",
      "4 Burglary\n",
      "5 Explosion\n",
      "6 Fighting\n",
      "7 NormalVideos\n",
      "8 RoadAccidents\n",
      "9 Robbery\n",
      "10 Shooting\n",
      "11 Shoplifting\n",
      "12 Stealing\n",
      "13 Vandalism\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create and fit label encoder on training labels\n",
    "le = LabelEncoder()\n",
    "train['label_idx'] = le.fit_transform(train['label'])\n",
    "\n",
    "# Apply the same encoding to test labels\n",
    "test['label_idx'] = le.transform(test['label'])\n",
    "\n",
    "# Number of classes and mapping\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Class name vs label_idx:\")\n",
    "for index, cls in enumerate(le.classes_):\n",
    "    print(index, cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5971e0e",
   "metadata": {},
   "source": [
    "We can see that the dataset has a large class imbalance. To mitigate this, we can do some under/oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca58a66",
   "metadata": {},
   "source": [
    "## Add Video Column ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274dd95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(path_str):\n",
    "    stem = pathlib.Path(path_str).stem\n",
    "\n",
    "    # split off the last chunk\n",
    "    video_id = stem.rsplit(\"_\", 1)[0]\n",
    "\n",
    "    return video_id\n",
    "\n",
    "train['video_id'] = train['image'].apply(extract_video_id)\n",
    "test['video_id']  = test['image'].apply(extract_video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e64b9c",
   "metadata": {},
   "source": [
    "## Split Train Into Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b54d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num train videos: 1288\n",
      "Num val videos: 322\n",
      "Train frames: 979795\n",
      "Val frames: 286550\n",
      "Test frames: 111308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "unique_videos = train['video_id'].unique()\n",
    "\n",
    "video_labels = (\n",
    "    train.groupby('video_id')['label_idx'].agg(lambda x: np.bincount(x).argmax()).reindex(unique_videos)\n",
    ")\n",
    "\n",
    "# 80% train 20% val\n",
    "train_vids, val_vids = train_test_split(\n",
    "    unique_videos,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=video_labels\n",
    ")\n",
    "\n",
    "train_df_raw = train[train['video_id'].isin(train_vids)].reset_index(drop=True)\n",
    "val = train[train['video_id'].isin(val_vids)].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nNum train videos:\", len(train_vids))\n",
    "print(\"Num val videos:\", len(val_vids))\n",
    "print(\"Train frames:\", len(train_df_raw))\n",
    "print(\"Val frames:\", len(val))\n",
    "print(\"Test frames:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc906b90",
   "metadata": {},
   "source": [
    "## Under/Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 10000\n",
    "\n",
    "def balance_dataset(df):\n",
    "    balanced_parts = []\n",
    "\n",
    "    for cls, group in df.groupby(\"label\"):\n",
    "        count = len(group)\n",
    "\n",
    "        if count > TARGET:\n",
    "            # Undersample to 10,000\n",
    "            group = group.sample(\n",
    "                n=TARGET,\n",
    "                replace=False,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        balanced_parts.append(group)\n",
    "\n",
    "    return pd.concat(balanced_parts).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train = balance_dataset(train_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ed6baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Burglary         10000\n",
      "Vandalism        10000\n",
      "Explosion        10000\n",
      "Robbery          10000\n",
      "Arson            10000\n",
      "NormalVideos     10000\n",
      "Abuse            10000\n",
      "Stealing         10000\n",
      "Assault          10000\n",
      "Fighting         10000\n",
      "RoadAccidents    10000\n",
      "Shooting         10000\n",
      "Shoplifting      10000\n",
      "Arrest           10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8515e6",
   "metadata": {},
   "source": [
    "## Set up PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc63326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Set constants for PyTorch\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc30e6",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6011a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation to training dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)),\n",
    "    transforms.ColorJitter(contrast=0.1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Simple transforms to val/test dataset\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e9538",
   "metadata": {},
   "source": [
    "## Create Pipeline For PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5208926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrimeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image']\n",
    "        label = int(row['label_idx'])\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Transform if needed (might not need for val/test)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d578ed",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c84a4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert to CrimeDataset classes\n",
    "train_dataset = CrimeDataset(train, train_transform)\n",
    "val_dataset = CrimeDataset(val, eval_transform)\n",
    "test_dataset = CrimeDataset(test, eval_transform)\n",
    "\n",
    "# Transform to DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd9865",
   "metadata": {},
   "source": [
    "## Create CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42516277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)      \n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)      \n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)      \n",
    "\n",
    "        self.flatten_dim = 128 * 8 * 8\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)            \n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = Net(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7202c",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b4d563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73940376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b62813",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m test(model, val_loader, criterion, device)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jacki\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    830\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    831\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = test(model, val_loader, criterion, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{EPOCHS} | \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
